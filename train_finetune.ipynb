{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ec6bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning==1.6.1\n",
      "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from pytorch_lightning==1.6.1) (22.0)\n",
      "Collecting torch>=1.8.*\n",
      "  Using cached torch-1.13.1-cp310-none-macosx_11_0_arm64.whl (53.2 MB)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting numpy>=1.17.2\n",
      "  Downloading numpy-1.24.1-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard>=2.2.0\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from pytorch_lightning==1.6.1) (6.0)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Using cached torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.3-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.6.1) (0.38.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.6.1) (65.6.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.51.1.tar.gz (22.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.6.1) (22.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp310-cp310-macosx_11_0_arm64.whl (57 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.6.1) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.6.1) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch_lightning==1.6.1) (2.1.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: grpcio\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.51.1-cp310-cp310-macosx_11_0_arm64.whl size=3409656 sha256=a88f99a7fd881416653e8b22daf777a213cad7a9b7919dd98d34e121c423c2f9\n",
      "  Stored in directory: /Users/damian/Library/Caches/pip/wheels/da/d4/cb/6efeb945322607b9ba647f6a3d0838aaae2b9a352a8cf0ed14\n",
      "Successfully built grpcio\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, urllib3, typing-extensions, tqdm, tensorboard-data-server, rsa, pyDeprecate, pyasn1-modules, protobuf, oauthlib, numpy, multidict, markdown, grpcio, fsspec, frozenlist, charset-normalizer, certifi, cachetools, async-timeout, absl-py, yarl, torch, requests, google-auth, aiosignal, torchmetrics, requests-oauthlib, aiohttp, google-auth-oauthlib, tensorboard, pytorch_lightning\n",
      "Successfully installed absl-py-1.3.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 cachetools-5.2.0 certifi-2022.12.7 charset-normalizer-2.1.1 frozenlist-1.3.3 fsspec-2022.11.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 markdown-3.4.1 multidict-6.0.4 numpy-1.24.1 oauthlib-3.2.2 protobuf-3.20.3 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch_lightning-1.6.1 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.13.1 torchmetrics-0.11.0 tqdm-4.64.1 typing-extensions-4.4.0 urllib3-1.26.13 werkzeug-2.2.2 yarl-1.8.2\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp310-cp310-macosx_12_0_arm64.whl (3.7 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from transformers) (1.24.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp310-cp310-macosx_11_0_arm64.whl (287 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->transformers) (3.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.9.0 huggingface-hub-0.11.1 regex-2022.10.31 tokenizers-0.13.2 transformers-4.25.1\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-req-build-ptnmhfnp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-req-build-ptnmhfnp\n",
      "  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: regex in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from clip==1.0) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from clip==1.0) (4.64.1)\n",
      "Requirement already satisfied: torch in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from clip==1.0) (1.13.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.1-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from torch->clip==1.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.1)\n",
      "Requirement already satisfied: requests in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.28.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.13)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369370 sha256=be99ecfa84f61c2fafca7b24beb8eb9abee395493f0bdfc78cd21b1d0e2319a9\n",
      "  Stored in directory: /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-ephem-wheel-cache-a54cj954/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
      "Successfully built clip\n",
      "Installing collected packages: pillow, ftfy, torchvision, clip\n",
      "Successfully installed clip-1.0 ftfy-6.1.1 pillow-9.4.0 torchvision-0.14.1\n",
      "Collecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup\n",
      "  Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-req-build-tslkbrj7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-req-build-tslkbrj7\n",
      "  Resolved https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to commit 12d03c07553aedd3d9e9155e2b3e31ce8c64081a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cosine-annealing-warmup\n",
      "  Building wheel for cosine-annealing-warmup (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cosine-annealing-warmup: filename=cosine_annealing_warmup-2.0-py3-none-any.whl size=4167 sha256=1cf139bcfe8432d95db48e451a24646d2b7b3a6690d9bb402f90e0a97e7dc3b5\n",
      "  Stored in directory: /private/var/folders/4d/jmm4mhxs6dxdcwltwb1rs7mr0000gn/T/pip-ephem-wheel-cache-1yqbza77/wheels/29/26/10/bf1a07417dd54aa73bdf09ce4f31c187974a444a1cedddbd99\n",
      "Successfully built cosine-annealing-warmup\n",
      "Installing collected packages: cosine-annealing-warmup\n",
      "Successfully installed cosine-annealing-warmup-2.0\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (1.24.1)\n",
      "Requirement already satisfied: six>=1.10 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (4.64.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-7.0.0-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from kaggle) (1.26.13)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages (from requests->kaggle) (2.1.1)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73031 sha256=c342a1df42fb2ffa98de320c5e9dae34a56f3f708cd9599fa70b6f681908654e\n",
      "  Stored in directory: /Users/damian/Library/Caches/pip/wheels/fb/01/d5/daa97ea9d89ceec9c6c76fad6fe97165661fd2236c46f83354\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-7.0.0 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning==1.6.1 \n",
    "!pip install transformers \n",
    "!pip install git+https://github.com/openai/CLIP.git \n",
    "!pip install git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup \n",
    "!pip install kaggle numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af099c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of the model checkpoint at johngiorgi/declutr-sci-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:689: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.\n",
      "  rank_zero_warn(\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "Missing logger folder: /Users/damian/2.current/train-CLIP/lightning_logs\n",
      "found 22 image/text file pairs\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:2109: LightningDeprecationWarning: `Trainer.num_gpus` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.num_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:2077: LightningDeprecationWarning: `Trainer.num_processes` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.num_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:2093: LightningDeprecationWarning: `Trainer.tpu_cores` is deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.num_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "num_devices: 1\n",
      "raw dataset has 11 items -> with batch size 2, have 5 steps\n",
      "num_devices: 1\n",
      "raw dataset has 11 items -> with batch size 2, have 5 steps\n",
      "num training steps: 160, warmup steps: 10\n",
      "num_devices: 1\n",
      "raw dataset has 11 items -> with batch size 2, have 5 steps\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | model   | CLIP | 160 M \n",
      "1 | teacher | CLIP | 160 M \n",
      "---------------------------------\n",
      "321 M     Trainable params\n",
      "0         Non-trainable params\n",
      "321 M     Total params\n",
      "1,286.894 Total estimated model params size (MB)\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/damian/miniforge3/envs/clip-training/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:   0%|                                           | 0/11 [00:00<?, ?it/s]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-7.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-6.txt\n",
      "Epoch 0:   9%|▎  | 1/11 [00:17<02:51, 17.17s/it, v_num=0, loss=1.410, acc=0.250]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/9181402864_ced1fcc1bc_b.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-4.txt\n",
      "Epoch 0:  18%|▌  | 2/11 [00:34<02:34, 17.18s/it, v_num=0, loss=1.390, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1595491517730-1.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/new-zealand-circa-stamp-printed-new-zealand-shows-kiwiana-buzzy-bee-toy-circa-buzzy-bee-toy-233309736.txt\n",
      "Epoch 0:  27%|▊  | 3/11 [00:51<02:17, 17.17s/it, v_num=0, loss=1.490, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-2.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2.txt\n",
      "Epoch 0:  36%|█  | 4/11 [01:08<02:00, 17.22s/it, v_num=0, loss=1.400, acc=0.250]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2-2.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2-3.txt\n",
      "Epoch 0:  45%|█▎ | 5/11 [01:26<01:43, 17.20s/it, v_num=0, loss=1.410, acc=0.250]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-3.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-11.txt\n",
      "Epoch 0:  55%|█▋ | 6/11 [01:43<01:26, 17.20s/it, v_num=0, loss=1.430, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-10.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/76YMS3IX4XWCRWGROQB3NCM65E.txt\n",
      "Epoch 0:  64%|█▉ | 7/11 [02:00<01:08, 17.20s/it, v_num=0, loss=1.440, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/101_sdc13268.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/buzzy-bee-beach.txt\n",
      "Epoch 0:  73%|██▏| 8/11 [02:17<00:51, 17.19s/it, v_num=0, loss=1.410, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1654319705734.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1563328241857.txt\n",
      "Epoch 0:  82%|██▍| 9/11 [02:34<00:34, 17.21s/it, v_num=0, loss=1.350, acc=0.750]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-8.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1595491517730.txt\n",
      "Epoch 0:  91%|█▊| 10/11 [02:52<00:17, 17.23s/it, v_num=0, loss=1.360, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-9.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/0619-princess-diana-charles-william-new-zealand-toy-gt.txt\n",
      "Epoch 1: 100%|██| 11/11 [03:11<00:00, 17.39s/it, v_num=0, loss=1.340, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-7.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-6.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▏ | 1/11 [03:28<34:45, 208.56s/it, v_num=0, loss=1.400, acc=0.250]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/9181402864_ced1fcc1bc_b.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-4.txt\n",
      "Epoch 1:  18%|▎ | 2/11 [03:45<16:55, 112.83s/it, v_num=0, loss=1.360, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1595491517730-1.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/new-zealand-circa-stamp-printed-new-zealand-shows-kiwiana-buzzy-bee-toy-circa-buzzy-bee-toy-233309736.txt\n",
      "Epoch 1:  27%|▊  | 3/11 [04:02<10:47, 80.94s/it, v_num=0, loss=1.410, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-2.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2.txt\n",
      "Epoch 1:  36%|█  | 4/11 [04:19<07:34, 64.98s/it, v_num=0, loss=1.390, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2-2.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/1940s-zealand-genuine-buzzy-bee-pull_1_84807dc25057405b70518451f14842e2-3.txt\n",
      "Epoch 1:  45%|█▎ | 5/11 [04:37<05:32, 55.41s/it, v_num=0, loss=1.380, acc=0.500]reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-3.txt\n",
      "reading description from /Users/damian/2.current/stablediffusion/buzzybee/fullsize/s-l1600-11.txt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "images_root_folder = \"/Users/damian/2.current/stablediffusion/buzzybee/fullsize\"\n",
    "accelerator = \"cpu\"\n",
    "#accelerator = \"gpu\"\n",
    "image_size = 224\n",
    "!python train_finetune.py --folder {images_root_folder}  --batch_size 2 --image_size {image_size} \\\n",
    "    --accelerator {accelerator} --devices 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f4785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
